name: AutoBolt QA Automation Pipeline
# Based on Taylor's QA Framework Recommendations
# Implements comprehensive regression testing for production readiness

on:
  # Trigger on code changes
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master ]
  
  # Scheduled testing
  schedule:
    # Daily smoke tests at 6 AM UTC
    - cron: '0 6 * * *'
    # Weekly performance tests on Sundays at 2 AM UTC  
    - cron: '0 2 * * 0'
    # Monthly health checks on 1st day at 1 AM UTC
    - cron: '0 1 1 * *'
  
  # Manual trigger
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: true
        default: 'SMOKE'
        type: choice
        options:
        - SMOKE
        - FULL_QA
        - PERFORMANCE
        - HEALTH_CHECK
      environment:
        description: 'Test environment'
        required: true
        default: 'development'
        type: choice
        options:
        - development
        - staging
        - production

env:
  NODE_VERSION: '18'
  CHROME_VERSION: 'stable'

jobs:
  # Determine test suite based on trigger
  determine-suite:
    runs-on: ubuntu-latest
    outputs:
      test_suite: ${{ steps.suite.outputs.suite }}
      is_scheduled: ${{ steps.suite.outputs.is_scheduled }}
      environment: ${{ steps.suite.outputs.environment }}
    steps:
      - name: Determine test suite
        id: suite
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "suite=${{ github.event.inputs.test_suite }}" >> $GITHUB_OUTPUT
            echo "is_scheduled=false" >> $GITHUB_OUTPUT
            echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" = "schedule" ]; then
            # Determine suite based on cron schedule
            if [ "${{ github.event.schedule }}" = "0 6 * * *" ]; then
              echo "suite=SMOKE" >> $GITHUB_OUTPUT
            elif [ "${{ github.event.schedule }}" = "0 2 * * 0" ]; then
              echo "suite=PERFORMANCE" >> $GITHUB_OUTPUT
            elif [ "${{ github.event.schedule }}" = "0 1 1 * *" ]; then
              echo "suite=HEALTH_CHECK" >> $GITHUB_OUTPUT
            fi
            echo "is_scheduled=true" >> $GITHUB_OUTPUT
            echo "environment=production" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "suite=FULL_QA" >> $GITHUB_OUTPUT
            echo "is_scheduled=false" >> $GITHUB_OUTPUT
            echo "environment=staging" >> $GITHUB_OUTPUT
          else
            echo "suite=SMOKE" >> $GITHUB_OUTPUT
            echo "is_scheduled=false" >> $GITHUB_OUTPUT
            echo "environment=development" >> $GITHUB_OUTPUT
          fi

  # Smoke Tests - 15 minutes
  smoke-tests:
    runs-on: ubuntu-latest
    needs: determine-suite
    if: needs.determine-suite.outputs.test_suite == 'SMOKE'
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: |
          npm ci
          npm install --save-dev puppeteer
          
      - name: Setup Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: ${{ env.CHROME_VERSION }}
          
      - name: Create test directories
        run: |
          mkdir -p test-reports
          mkdir -p test-alerts
          
      - name: Run smoke tests
        run: |
          echo "üöÄ Running Daily Smoke Tests (Target: 15 minutes)"
          node automated-testing-pipeline.js SMOKE
          
      - name: Upload smoke test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: smoke-test-results
          path: |
            test-reports/
            test-alerts/
          retention-days: 30
          
      - name: Check smoke test success
        run: |
          if [ -f "test-reports/latest-smoke-results.json" ]; then
            SUCCESS_RATE=$(node -e "console.log(JSON.parse(require('fs').readFileSync('test-reports/latest-smoke-results.json')).successRate)")
            if [ $(echo "$SUCCESS_RATE < 95" | bc) -eq 1 ]; then
              echo "‚ùå Smoke tests failed: $SUCCESS_RATE% success rate (required: 95%)"
              exit 1
            else
              echo "‚úÖ Smoke tests passed: $SUCCESS_RATE% success rate"
            fi
          fi

  # Full QA Suite - 60 minutes  
  full-qa-tests:
    runs-on: ubuntu-latest
    needs: determine-suite
    if: needs.determine-suite.outputs.test_suite == 'FULL_QA'
    timeout-minutes: 75
    
    strategy:
      matrix:
        test_batch: [1, 2, 3] # Parallel execution for faster results
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: |
          npm ci
          npm install --save-dev puppeteer jest lighthouse
          
      - name: Setup Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: ${{ env.CHROME_VERSION }}
          
      - name: Create test directories
        run: |
          mkdir -p test-reports
          mkdir -p test-alerts
          mkdir -p test-coverage
          
      - name: Run full QA suite batch ${{ matrix.test_batch }}
        run: |
          echo "üî¨ Running Pre-Release QA Suite Batch ${{ matrix.test_batch }} (Target: 60 minutes total)"
          node automated-testing-pipeline.js FULL_QA --batch=${{ matrix.test_batch }}
          
      - name: Upload QA test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: qa-test-results-batch-${{ matrix.test_batch }}
          path: |
            test-reports/
            test-alerts/
            test-coverage/
          retention-days: 90

  # Aggregate QA Results
  aggregate-qa-results:
    runs-on: ubuntu-latest
    needs: [determine-suite, full-qa-tests]
    if: needs.determine-suite.outputs.test_suite == 'FULL_QA' && always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Download all QA artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: qa-test-results-batch-*
          merge-multiple: true
          
      - name: Aggregate QA results
        run: |
          echo "üìä Aggregating Full QA Suite Results"
          node -e "
          const fs = require('fs');
          const results = [];
          for (let i = 1; i <= 3; i++) {
            if (fs.existsSync(\`test-reports/qa-batch-\${i}.json\`)) {
              results.push(JSON.parse(fs.readFileSync(\`test-reports/qa-batch-\${i}.json\`)));
            }
          }
          const aggregated = {
            timestamp: new Date().toISOString(),
            totalBatches: results.length,
            overallSuccessRate: results.reduce((sum, r) => sum + r.successRate, 0) / results.length,
            results: results
          };
          fs.writeFileSync('test-reports/aggregated-qa-results.json', JSON.stringify(aggregated, null, 2));
          console.log(\`Overall QA Success Rate: \${aggregated.overallSuccessRate.toFixed(1)}%\`);
          "
          
      - name: Check QA success criteria
        run: |
          if [ -f "test-reports/aggregated-qa-results.json" ]; then
            SUCCESS_RATE=$(node -e "console.log(JSON.parse(require('fs').readFileSync('test-reports/aggregated-qa-results.json')).overallSuccessRate)")
            if [ $(echo "$SUCCESS_RATE < 90" | bc) -eq 1 ]; then
              echo "‚ùå Full QA suite failed: $SUCCESS_RATE% success rate (required: 90%)"
              echo "::error title=QA Failure::Full QA suite below threshold: $SUCCESS_RATE%"
              exit 1
            else
              echo "‚úÖ Full QA suite passed: $SUCCESS_RATE% success rate"
            fi
          fi
          
      - name: Upload aggregated results
        uses: actions/upload-artifact@v4
        with:
          name: aggregated-qa-results
          path: test-reports/aggregated-qa-results.json
          retention-days: 180

  # Performance Tests - 30 minutes
  performance-tests:
    runs-on: ubuntu-latest
    needs: determine-suite
    if: needs.determine-suite.outputs.test_suite == 'PERFORMANCE'
    timeout-minutes: 40
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: |
          npm ci
          npm install --save-dev puppeteer lighthouse clinic autocannon
          
      - name: Setup Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: ${{ env.CHROME_VERSION }}
          
      - name: Create test directories
        run: |
          mkdir -p test-reports
          mkdir -p performance-data
          
      - name: Run performance tests
        run: |
          echo "‚ö° Running Weekly Performance Validation (Target: 30 minutes)"
          node automated-testing-pipeline.js PERFORMANCE
          
      - name: Generate performance report
        run: |
          echo "üìà Generating performance benchmarks"
          # Run Lighthouse audits on test pages
          if [ -f "test-data/performance-urls.json" ]; then
            node -e "
            const lighthouse = require('lighthouse');
            const chromeLauncher = require('chrome-launcher');
            const fs = require('fs');
            
            async function runLighthouse() {
              const chrome = await chromeLauncher.launch({chromeFlags: ['--headless']});
              const options = {logLevel: 'info', output: 'json', port: chrome.port};
              const runnerResult = await lighthouse('http://localhost:8080/test-form.html', options);
              
              const report = {
                timestamp: new Date().toISOString(),
                performance: runnerResult.lhr.categories.performance.score * 100,
                accessibility: runnerResult.lhr.categories.accessibility.score * 100,
                bestPractices: runnerResult.lhr.categories['best-practices'].score * 100,
                seo: runnerResult.lhr.categories.seo.score * 100
              };
              
              fs.writeFileSync('performance-data/lighthouse-report.json', JSON.stringify(report, null, 2));
              await chrome.kill();
            }
            
            runLighthouse().catch(console.error);
            "
          fi
          
      - name: Check performance thresholds
        run: |
          if [ -f "test-reports/performance-results.json" ]; then
            node -e "
            const results = JSON.parse(require('fs').readFileSync('test-reports/performance-results.json'));
            const thresholds = {
              loadTime: 3000,
              memoryUsage: 100, // MB
              successRate: 80
            };
            
            let failed = false;
            if (results.averageLoadTime > thresholds.loadTime) {
              console.log(\`‚ùå Load time threshold exceeded: \${results.averageLoadTime}ms > \${thresholds.loadTime}ms\`);
              failed = true;
            }
            if (results.successRate < thresholds.successRate) {
              console.log(\`‚ùå Success rate below threshold: \${results.successRate}% < \${thresholds.successRate}%\`);
              failed = true;
            }
            
            if (failed) {
              process.exit(1);
            } else {
              console.log('‚úÖ All performance thresholds met');
            }
            "
          fi
          
      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-test-results
          path: |
            test-reports/
            performance-data/
          retention-days: 90

  # Health Check Tests - 45 minutes
  health-check-tests:
    runs-on: ubuntu-latest
    needs: determine-suite
    if: needs.determine-suite.outputs.test_suite == 'HEALTH_CHECK'
    timeout-minutes: 55
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: |
          npm ci
          npm install --save-dev puppeteer axios cheerio
          
      - name: Setup Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: ${{ env.CHROME_VERSION }}
          
      - name: Create test directories
        run: |
          mkdir -p test-reports
          mkdir -p health-reports
          
      - name: Run health check tests
        run: |
          echo "üè• Running Monthly Health Checks (Target: 45 minutes)"
          node automated-testing-pipeline.js HEALTH_CHECK
          
      - name: Directory accessibility scan
        run: |
          echo "üîç Scanning all directory URLs for accessibility"
          node -e "
          const fs = require('fs');
          const axios = require('axios');
          
          async function scanDirectories() {
            const dirs = JSON.parse(fs.readFileSync('directories/expanded-master-directory-list.json'));
            const results = [];
            
            for (const dir of dirs.directories.slice(0, 20)) {
              try {
                const response = await axios.get(dir.url, { timeout: 10000 });
                results.push({
                  name: dir.name,
                  url: dir.url,
                  status: 'ACCESSIBLE',
                  responseCode: response.status,
                  responseTime: response.headers['x-response-time'] || 'N/A'
                });
              } catch (error) {
                results.push({
                  name: dir.name,
                  url: dir.url,
                  status: 'FAILED',
                  error: error.message
                });
              }
            }
            
            const report = {
              timestamp: new Date().toISOString(),
              totalScanned: results.length,
              accessible: results.filter(r => r.status === 'ACCESSIBLE').length,
              failed: results.filter(r => r.status === 'FAILED').length,
              results: results
            };
            
            fs.writeFileSync('health-reports/directory-scan.json', JSON.stringify(report, null, 2));
            console.log(\`Directory scan complete: \${report.accessible}/\${report.totalScanned} accessible\`);
          }
          
          scanDirectories().catch(console.error);
          "
          
      - name: Upload health check results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: health-check-results
          path: |
            test-reports/
            health-reports/
          retention-days: 180

  # Notification and Reporting
  notify-results:
    runs-on: ubuntu-latest
    needs: [determine-suite, smoke-tests, aggregate-qa-results, performance-tests, health-check-tests]
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Download test artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*-test-results*'
          merge-multiple: true
          
      - name: Generate summary report
        run: |
          echo "üìä Generating Test Execution Summary"
          node -e "
          const fs = require('fs');
          const summary = {
            timestamp: new Date().toISOString(),
            suite: '${{ needs.determine-suite.outputs.test_suite }}',
            trigger: '${{ github.event_name }}',
            environment: '${{ needs.determine-suite.outputs.environment }}',
            results: {}
          };
          
          // Collect available results
          const resultFiles = {
            'smoke': 'test-reports/latest-smoke-results.json',
            'qa': 'test-reports/aggregated-qa-results.json',
            'performance': 'test-reports/performance-results.json',
            'health': 'test-reports/health-check-results.json'
          };
          
          for (const [type, file] of Object.entries(resultFiles)) {
            if (fs.existsSync(file)) {
              summary.results[type] = JSON.parse(fs.readFileSync(file));
            }
          }
          
          fs.writeFileSync('test-summary.json', JSON.stringify(summary, null, 2));
          
          console.log('=== AutoBolt QA Test Summary ===');
          console.log(\`Suite: \${summary.suite}\`);
          console.log(\`Trigger: \${summary.trigger}\`);
          console.log(\`Environment: \${summary.environment}\`);
          
          for (const [type, result] of Object.entries(summary.results)) {
            console.log(\`\${type.toUpperCase()}: \${result.successRate || 'N/A'}% success rate\`);
          }
          "
          
      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('test-summary.json')) {
              const summary = JSON.parse(fs.readFileSync('test-summary.json', 'utf8'));
              
              let comment = '## üß™ AutoBolt QA Test Results\\n\\n';
              comment += `**Suite:** ${summary.suite}\\n`;
              comment += `**Environment:** ${summary.environment}\\n`;
              comment += `**Timestamp:** ${summary.timestamp}\\n\\n`;
              
              comment += '### Results:\\n';
              for (const [type, result] of Object.entries(summary.results)) {
                const emoji = result.successRate >= 90 ? '‚úÖ' : '‚ùå';
                comment += `${emoji} **${type.toUpperCase()}:** ${result.successRate}% success rate\\n`;
              }
              
              comment += '\\n---\\n';
              comment += '*Generated by AutoBolt QA Automation Pipeline*';
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }
            
      - name: Upload final summary
        uses: actions/upload-artifact@v4
        with:
          name: test-execution-summary
          path: test-summary.json
          retention-days: 365

  # Security and cleanup
  cleanup:
    runs-on: ubuntu-latest
    needs: [notify-results]
    if: always()
    
    steps:
      - name: Cleanup temporary files
        run: |
          echo "üßπ Cleaning up temporary test files"
          # In a real implementation, this would clean up any sensitive test data
          echo "Cleanup completed"